{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2be0f25-ef19-4f9c-b6c3-6cd963f2a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from load_data.prepared_custom_ds import CustomDataset\n",
    "from utilities.config_load import load_config\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37dfc710-3e9e-4245-8767-4e5a1399b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"configs/\"\n",
    "config = load_config(CONFIG_PATH, \"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4b677b-49d8-4f45-82ed-033d487aad98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'train_img_path': 'dataset/train_v2',\n",
       "  'test_img_path': 'dataset/test_v2',\n",
       "  'mask_path': 'dataset/train_masks',\n",
       "  'reshaped_img_path': 'dataset/reshaped_img',\n",
       "  'dir_path': 'dataset'},\n",
       " 'original_img_size': 768,\n",
       " 'new_img_size': 256,\n",
       " 'project_path': 'C:/Users/da4nik/Segmentation',\n",
       " 'model': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79161ad9-479e-40b8-9473-af4378778422",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ac38d-367f-4924-a94a-ecc8e828b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(first_chanels, second_chanels, kernel_size, dropout_rate):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(first_chanels),\n",
    "        nn.Conv2d(first_chanels, second_chanels, kernel_size, padding='same'),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.BatchNorm2d(second_chanels),\n",
    "        nn.Conv2d(second_chanels, second_chanels, kernel_size, padding='same'),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2235b-57a9-4deb-a622-32b084af51aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_Encoder(nn.Module):\n",
    "    def __init__(self, kernel_size, dropout_rate, nkernels):\n",
    "        super(Unet_Encoder, self).__init___()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropuut_rate = dropuut_rate\n",
    "        self.nkernels = nkernels\n",
    "        self.conv1 = ConvBlock(3, nkernels, self.kernel_size, self.dropout_rate)\n",
    "        self.conv2 = ConvBlock(nkernels, nkernels*2, self.kernel_size, self.dropout_rate)\n",
    "        self.conv3 = ConvBlock(nkernels*2, nkernels*4, self.kernel_size, self.dropout_rate)\n",
    "        self.conv4 = ConvBlock(nkernels*4, nkernels*8, self.kernel_size, self.dropout_rate)\n",
    "        self.maxpool_list = nn.ModuleList([nn.MaxPool2d(kernel_size=2) for _ in range(4)])\n",
    "        self.conv_list = nn.ModuleList([self.conv1, self.conv2, self.conv3, self.conv4])\n",
    "\n",
    "    def init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0.01)\n",
    "\n",
    "    def forward(self, input):\n",
    "        list_skips = list()\n",
    "        for i in range(4):\n",
    "            skip = self.self.conv_list[i](input)\n",
    "            input = self.maxpool_list[i](skip1)\n",
    "            list_skips.append(skip)\n",
    "        return input, list_skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17548d-5952-44b6-9c80-197f5e78ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_Decoder(nn.Module):\n",
    "    def __init__(self, kernel_size, dropout_rate, nkernels):\n",
    "        super(Unet_Decoder, self).__init___()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout_rate = dropuut_rate\n",
    "        self.nkernels = nkernels\n",
    "        self.conv5 = ConvBlock(nkernels*8, nkernels*16, self.kernel_size, self.dropout_rate)\n",
    "        self.conv6 = ConvBlock(nkernels*16, nkernels*8, self.kernel_size, self.dropout_rate)\n",
    "        self.conv7 = ConvBlock(nkernels*8, nkernels*4, self.kernel_size, self.dropout_rate)\n",
    "        self.conv8 = ConvBlock(nkernels*4, nkernels*2, self.kernel_size, self.dropout_rate)\n",
    "        self.conv_list = nn.ModuleList([self.conv5, self.conv6, self.conv7, self.conv8])\n",
    "        self.convt_list = nn.ModuleList([nn.ConvTranspose2d(nkernels*(2**(4-i)), nkernels*((2**(4-i))//2), kernel_size=(2, 2), stride=(2, 2)) \n",
    "                                           for i in range(4)])\n",
    "\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.Conv2d, nn.ConvTranspose2d)):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0.01)\n",
    "\n",
    "    \n",
    "    def forward(self, input, list_skips):\n",
    "        for i in range(4):\n",
    "            if i==0:\n",
    "                out = self.conv_list[i](input)\n",
    "                out = self.convt_list[i](out)\n",
    "            else:\n",
    "                out = self.conv_list[i](torch.cat((out, list_skips[4-i]), 0))\n",
    "                out = self.convt_list[i](out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f3734-7c7d-477c-8f1b-02a2729af086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Unet(nn.Module):\n",
    "    def __init__(self, kernel_size, dropout_rate, nkernels, output_chanels):\n",
    "        super(Model_Unet, self).__init___()\n",
    "        self.output_chanels = output_chanels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout_rate = dropuut_rate\n",
    "        self.nkernels = nkernels\n",
    "        self.enc_layer = Unet_Encoder(self.kernel_size, self.dropout_rate, self.nkernels)\n",
    "        self.dec_layer = Unet_Decoder(self.kernel_size, self.dropout_rate, self.nkernels)\n",
    "        self.conv9 = ConvBlock(self.nkernels*2, self.nkernels, self.kernel_size, self.dropout_rate)\n",
    "        self.conv10 = nn.Conv2d(self.nkernels, self.output_chanels, (1, 1), padding='same')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0.01)\n",
    "\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out, list_skips = self.enc_layer(input)\n",
    "        out = self.dec_layer(out, list_skips)\n",
    "        out = self.conv9[i](torch.cat((out, list_skips[0]), 0))\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa92cd3-f627-49bb-a439-437f700c3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X_train, y_train)\n",
    "vdataset = CustomDataset(X_test, y_test)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=12, num_workers=0, shuffle=True) # + num thread num_workers=6,\n",
    "vdataloader = torch.utils.data.DataLoader(vdataset, batch_size=12, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c5adc-4d0c-4ced-9c28-e891a8326d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, loss_fn, opt, loader):\n",
    "    loss_per_batches = 0\n",
    "    elapsed = 0\n",
    "    start_epoch2 = time.time()\n",
    "    for i, data in enumerate(loader):\n",
    "\n",
    "        start_epoch = time.time()\n",
    "        features, labels = data\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        y_pred = model(features)\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        loss_per_batches += loss\n",
    "        \n",
    "        end_epoch = time.time()\n",
    "        elapsed += (end_epoch - start_epoch)\n",
    "        \n",
    "    print(\"train = \" + str(elapsed))\n",
    "    print(\"train + load = \" + str(time.time() - start_epoch2))\n",
    "    return loss_per_batches/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7281747-1f6d-4bf2-9201-077f8fdfacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, opt, train_loader, val_loader, save_treshold=10, epochs=50, model_name='model_name'):\n",
    "        \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    writer = SummaryWriter('runs/' + model_name + '_{}'.format(timestamp))\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=3, verbose=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_epoch = time.time()\n",
    "        print('EPOCH {}:'.format(epoch + 1))\n",
    "        \n",
    "        model.train()\n",
    "        avg_loss = train_step(model, loss_fn, opt, train_loader)\n",
    "        model.eval()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3c46c-e6d1-4604-8952-ae0fc197ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_Unet(kernel_size=3, dropout_rate=0.15, nkernels=2, output_chanels=1)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b96238e-6f56-49ff-ad40-dbb337aeec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90d4f8a-afb6-46a5-8219-efba9671f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = loss_fun(torch.zeros(1, 200, 200), torch.ones(1, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c2dd7f-0e3b-41e1-bc89-a43b69e94032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a53af7dd-f56b-4351-9c69-84eb2311bab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 => 8\n",
      "8 => 4\n",
      "4 => 2\n",
      "2 => 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(str(2**(4-i)) + \" => \" + str((2**(4-i))//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c20bae-5eb1-46cc-93c4-2d04caa62cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max = nn.MaxPool2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db4567af-bc8d-4ddb-ae6f-bc3bac28195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = nn.ConvTranspose2d(16, 16//2, kernel_size=(2, 2), stride=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137ec1f0-fcfc-4853-93b3-67c96afbfc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = max(torch.zeros(16, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc500487-ea3f-49fc-9776-21d2e8ed34bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 100])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8fec0b9-c395-476f-8752-d8a9af8cf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ct(torch.zeros(16, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89e94b00-06ba-4514-969b-1d0369b549f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 400, 400])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e117d-59d3-45dc-8939-97c190fb0272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
